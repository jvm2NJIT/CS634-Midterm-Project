{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = ['Shampoo', 'Apple', 'Banana', 'Milk', 'Eggs', 'Soap', 'Bacon', 'Sugar', 'Water', 'Yogurt']\n",
    "items = sorted(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findsubsets(s, k):\n",
    "    '''\n",
    "    Returns all k-itemsets from list s\n",
    "    Parameters:\n",
    "        s (list): List of items\n",
    "        k (int): Size of subsets you wish to find\n",
    "    Returns:\n",
    "        subsets (list): List of k-subsets\n",
    "    '''\n",
    "    return list(itertools.combinations(s, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_possible_rules(freq):\n",
    "    '''\n",
    "    Returns possible association rules from an itemset\n",
    "    Parameters:\n",
    "        freq (tuple): Frequent itemset\n",
    "    Returns:\n",
    "        possible_rules (list): List of possible rules\n",
    "    '''\n",
    "    n = len(freq)\n",
    "    possible_rules = []\n",
    "    for i in range(1, n):\n",
    "        for combo in itertools.combinations(freq, i):\n",
    "            tuple1 = combo\n",
    "            tuple2 = tuple(item for item in freq if item not in combo)\n",
    "            possible_rules.append([tuple1, tuple2])\n",
    "    return possible_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brute_force(items, filename, support, confidence):\n",
    "    '''\n",
    "    Uses brute force method to generate frequent items and generate association rules\n",
    "    Paramaters:\n",
    "        items (list): Sorted list of items\n",
    "        filename (str): Filename of database you want to read from\n",
    "        support (float): Desired support level for finding frequent itemsets\n",
    "        confidence (float): Desired support level for finding association rules\n",
    "    Returns:\n",
    "        [freq_itemsets, rules, sups, cons] (list): A list of frequent items, a list of association rules, and their corresponding support values and confidence values\n",
    "    '''\n",
    "    df = pd.read_csv(filename)\n",
    "    freq_itemsets = []\n",
    "    supports = {}\n",
    "    sups = []\n",
    "    cons = []\n",
    "\n",
    "    for i in range (1, 11):\n",
    "        i_sets = findsubsets(items, i)\n",
    "        for subset in i_sets:\n",
    "            freq_count = 0\n",
    "            for ind in df.index:\n",
    "                match = True\n",
    "                for item in subset:\n",
    "                    if not df[item][ind]:\n",
    "                        match = False\n",
    "                        break\n",
    "                if match:\n",
    "                    freq_count = freq_count + 1\n",
    "\n",
    "            supports.update({subset: freq_count / 20})\n",
    "            if freq_count / 20 >= support:\n",
    "                freq_itemsets.append(subset)\n",
    "                sups.append(freq_count / 20)\n",
    "    \n",
    "    rules = []\n",
    "    for freq in freq_itemsets:\n",
    "        possible_rules = generate_possible_rules(freq)\n",
    "        for p in possible_rules:\n",
    "            X = p[0]\n",
    "            Y = p[1]\n",
    "            X_and_Y = tuple(sorted(X+Y))\n",
    "            if supports[X_and_Y] / supports[X] >= confidence:\n",
    "                rules.append(p)\n",
    "                cons.append(supports[X_and_Y] / supports[X])\n",
    "\n",
    "    \n",
    "    return([freq_itemsets, rules, sups, cons])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequent itemsets for Database1.csv with support 0.5 and confidence 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Apple',),\n",
       " ('Banana',),\n",
       " ('Eggs',),\n",
       " ('Soap',),\n",
       " ('Water',),\n",
       " ('Yogurt',),\n",
       " ('Soap', 'Water')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = brute_force(items, 'Database1.csv', 0.5, 0.75)\n",
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Soap',), ('Water',)], [('Water',), ('Soap',)]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
